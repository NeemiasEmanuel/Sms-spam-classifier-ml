# -*- coding: utf-8 -*-
"""ProvaDS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rvzg02Cq9_CJe4iuF2a2XTnlZnMdmm6B
"""

from google.colab import files


uploaded = files.upload()

import pandas as pd
import io

df = pd.read_csv(io.BytesIO(uploaded['SMSSpamCollection']),sep = '\t')
print(df)

df['target'] = df['target'].apply(lambda x: 1 if x == 'spam' else 0)

contagem_classes = df.groupby('target')['target'].count()

total = contagem_classes.sum()

porcentagem_classes = contagem_classes / total * 100
print(porcentagem_classes)

!pip install scikit-learn==1.2.2
import numpy as np
from sklearn.model_selection import train_test_split

X = df['text']
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer



X_train_indices = X_train.index
X_test_indices = X_test.index

X_train_text = df['text'].iloc[X_train_indices]
X_test_text = df['text'].iloc[X_test_indices]

vectorizer = TfidfVectorizer()

X_train_tfidf = vectorizer.fit_transform(X_train_text)

X_test_tfidf = vectorizer.transform(X_test_text)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train_tfidf, y_train)

y_pred = model.predict(X_test_tfidf)
y_pred

y_proba = model.predict_proba(X_test_tfidf)
y_proba[:,1][y_test==1]<0.72

y_proba_1 = y_proba[:,1]
y_proba_1

df_proba_1 = pd.DataFrame({'proba_1':y_proba_1})
df_proba_1

df_filtro_1 = pd.DataFrame({'prob_1':y_proba_1, 'y_test':y_test})
df_filtro_1

df_filtro_1_filtrado = df_filtro_1.loc[df_filtro_1['y_test'] == 1]
df_filtro_1_filtrado

df_filtro_1_filtrado2 = df_filtro_1.loc[df_filtro_1['y_test'] == 0]
df_filtro_1_filtrado2

import matplotlib.pyplot as plt
import seaborn as sns

pd.DataFrame(y_pred).hist()

plt.hist(df_filtro_1_filtrado2['prob_1'],
         bins=np.arange(0, 1.1, 0.1),
         color='green',
         weights=np.ones(len(df_filtro_1_filtrado2)) / len(df_filtro_1_filtrado2) * 100)

plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')
plt.xlabel('Probabilidade')
plt.ylabel('Percentual da população')
plt.title('Histograma de Probabilidades para Classe Negativa(ham)')
plt.xticks(ticks=np.arange(0, 1.1, 0.1))

plt.show()

plt.hist(df_filtro_1_filtrado['prob_1'],
         bins=np.arange(0, 1.1, 0.1),
         color='red',
         weights=np.ones(len(df_filtro_1_filtrado)) / len(df_filtro_1_filtrado) * 100)

plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')
plt.xlabel('Probabilidade')
plt.ylabel('Percentual da população')
plt.title('Histograma de Probabilidades para Classe Positiva (Spam)')
plt.xticks(ticks=np.arange(0, 1.1, 0.1))

plt.show()

plt.hist(y_proba_1,
         bins=np.arange(0, 1.1, 0.1),
         color='blue',
         weights=np.ones(len(y_proba_1)) / len(y_proba) * 100)
plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')
plt.xlabel('Probabilidade')
plt.ylabel('Percentual da população')
plt.title('Histograma de Probabilidades para População Geral')
plt.xticks(ticks=np.arange(0, 1.1, 0.1))

plt.show()

import matplotlib.pyplot as plt
import numpy as np

bins = np.arange(0, 1.1, 0.1)
bar_width = 0.04

limite_esquerdo = 0.1
limite_direito = 0.6

positiva_hist, _ = np.histogram(df_filtro_1_filtrado['prob_1'],
                                bins=bins,
                                weights=np.ones(len(df_filtro_1_filtrado)) / len(df_filtro_1_filtrado) * 100)

geral_hist, _ = np.histogram(y_proba_1,
                             bins=bins,
                             weights=np.ones(len(y_proba_1)) / len(y_proba) * 100)

plt.bar(bins[:-1] + bar_width/2, geral_hist, width=bar_width, color='blue', edgecolor='black', label='População Geral')
plt.bar(bins[:-1] + 1.5*bar_width, positiva_hist, width=bar_width, color='red', edgecolor='black', label='Classe Positiva (Spam)')

plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')

plt.axvline(x=limite_esquerdo, color='green', linestyle='--', lw=2, label='Limite Esquerdo (10%)')
plt.axvline(x=limite_direito, color='green', linestyle='--', lw=2, label='Limite Direito (60%)')


for i in range(len(bins) - 1):

    plt.text(bins[i] + bar_width/2, geral_hist[i] + 1, f'{geral_hist[i]:.1f}%', ha='center', va='bottom', fontsize=8, color='blue')

    plt.text(bins[i] + 1.5*bar_width, positiva_hist[i] + 1, f'{positiva_hist[i]:.1f}%', ha='center', va='bottom', fontsize=8, color='red')

plt.xlabel('Probabilidade (%)')
plt.ylabel('% da População')
plt.title('Distribuição das Probabilidades para População Geral e Classe Positiva')
plt.xticks(ticks=np.arange(0, 1.1, 0.1), labels=[f'{int(x*100)}%' for x in np.arange(0, 1.1, 0.1)])
plt.yticks(np.arange(0, 101, 10))

plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

zona_positiva_idx = np.where(bins[:-1] < limite_esquerdo)[0]
zona_negativa_idx = np.where(bins[:-1] > limite_direito)[0]
zona_mesa_idx = np.where((bins[:-1] >= limite_esquerdo) & (bins[:-1] <= limite_direito))[0]

soma_positiva_geral = np.sum(np.array(geral_hist)[zona_positiva_idx])
soma_positiva_spam = np.sum(np.array(positiva_hist)[zona_positiva_idx])

soma_negativa_geral = np.sum(np.array(geral_hist)[zona_negativa_idx])
soma_negativa_spam = np.sum(np.array(positiva_hist)[zona_negativa_idx])

soma_mesa_geral = np.sum(np.array(geral_hist)[zona_mesa_idx])
soma_mesa_spam = np.sum(np.array(positiva_hist)[zona_mesa_idx])

soma_total_geral = np.sum(geral_hist)
soma_total_spam = np.sum(positiva_hist)

porcent_positiva_geral = (soma_positiva_geral / soma_total_geral) * 100
porcent_positiva_spam = (soma_positiva_spam / soma_total_spam) * 100

porcent_negativa_geral = (soma_negativa_geral / soma_total_geral) * 100
porcent_negativa_spam = (soma_negativa_spam / soma_total_spam) * 100

porcent_mesa_geral = (soma_mesa_geral / soma_total_geral) * 100
porcent_mesa_spam = (soma_mesa_spam / soma_total_spam) * 100
plt.text(1.05, 50, f'Positiva: Geral {porcent_positiva_geral:.1f}%, Spam {porcent_positiva_spam:.1f}%', fontsize=10, color='green')
plt.text(1.05, 40, f'Mesa: Geral {porcent_mesa_geral:.1f}%, Spam {porcent_mesa_spam:.1f}%', fontsize=10, color='orange')
plt.text(1.05, 30, f'Negativa: Geral {porcent_negativa_geral:.1f}%, Spam {porcent_negativa_spam:.1f}%', fontsize=10, color='red')

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

TN, FP, FN, TP = cm.ravel()

plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])

plt.text(1.25, 1.25, f'TP={TP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
plt.text(0.25, 0.25, f'TN={TN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='white', weight='bold')
plt.text(0.25, 1.25, f'FP={FP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
plt.text(1.25, 0.25, f'FN={FN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')

plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão')
plt.show()

accuracy = (TP + TN) / (TP + TN + FP + FN)
precision = TP / (TP + FP) if (TP + FP) != 0 else 0
recall = TP / (TP + FN) if (TP + FN) != 0 else 0
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0

print("\nCálculos das Métricas:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

contagem_positiva = np.sum(y_pred == 1)
contagem_negativa = np.sum(y_pred == 0)

total_instancias = len(y_pred)

porcentagem_positiva = (contagem_positiva / total_instancias) * 100
porcentagem_negativa = (contagem_negativa / total_instancias) * 100

print(f"Porcentagem de instâncias positivas (Spam): {porcentagem_positiva:.2f}%")
print(f"Porcentagem de instâncias negativas (Ham): {porcentagem_negativa:.2f}%")

from sklearn import metrics

area = metrics.roc_auc_score(y_test,y_proba_1)

import matplotlib.pyplot as plt

fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba_1)
roc_auc = metrics.auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

precision, recall, _ = metrics.precision_recall_curve(y_test, y_proba_1)

auc_pr = metrics.average_precision_score(y_test, y_proba_1)

plt.figure()
plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % auc_pr)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

print(f"AUC-ROC: {roc_auc:.4f}")
print(f"AUC-PR: {auc_pr:.4f}")

###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
###################################################################################################################################################################################################################################
#########################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################cu

from sklearn.linear_model import LogisticRegression

model2 = LogisticRegression()

model2.fit(X_train_tfidf, y_train)

y_pred2 = model2.predict(X_test_tfidf)
y_pred2

y_proba2 = model2.predict_proba(X_test_tfidf)
y_proba2

y_proba_2 = y_proba2[:,1]
y_proba_2

df_proba_2 = pd.DataFrame({'proba_2':y_proba_2})
df_proba_2

df_filtro_2 = pd.DataFrame({'prob_2':y_proba_2, 'y_test':y_test})
df_filtro_2

df_filtro_2_filtrado = df_filtro_2.loc[df_filtro_2['y_test'] == 1]
df_filtro_2_filtrado

plt.hist(df_filtro_2_filtrado['prob_2'],
         bins=np.arange(0, 1.1, 0.1),
         color='red',
         weights=np.ones(len(df_filtro_2_filtrado)) / len(df_filtro_2_filtrado) * 100)

plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')
plt.xlabel('Probabilidade')
plt.ylabel('Percentual da população')
plt.title('Histograma de Probabilidades para Classe Positiva (Spam)')
plt.xticks(ticks=np.arange(0, 1.1, 0.1))

plt.show()

plt.hist(y_proba_2,
         bins=np.arange(0, 1.1, 0.1),
         color='blue',
         weights=np.ones(len(y_proba_2)) / len(y_proba2) * 100)
plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')
plt.xlabel('Probabilidade')
plt.ylabel('Percentual da população')
plt.title('Histograma de Probabilidades para População Geral')
plt.xticks(ticks=np.arange(0, 1.1, 0.1))

plt.show()

import matplotlib.pyplot as plt
import numpy as np

bins = np.arange(0, 1.1, 0.1)
bar_width = 0.04

limite_esquerdo = 0.2
limite_direito = 0.5

positiva_hist, _ = np.histogram(df_filtro_2_filtrado['prob_2'],
                                bins=bins,
                                weights=np.ones(len(df_filtro_2_filtrado)) / len(df_filtro_2_filtrado) * 100)

geral_hist, _ = np.histogram(y_proba_2,
                             bins=bins,
                             weights=np.ones(len(y_proba_2)) / len(y_proba2) * 100)

plt.bar(bins[:-1] + bar_width/2, geral_hist, width=bar_width, color='blue', edgecolor='black', label='População Geral')
plt.bar(bins[:-1] + 1.5*bar_width, positiva_hist, width=bar_width, color='red', edgecolor='black', label='Classe Positiva (Spam)')

plt.grid(True, which='both', axis='both', linestyle='--', linewidth=0.5, color='gray')

plt.axvline(x=limite_esquerdo, color='green', linestyle='--', lw=2, label='Limite Esquerdo (10%)')
plt.axvline(x=limite_direito, color='green', linestyle='--', lw=2, label='Limite Direito (60%)')


for i in range(len(bins) - 1):

    plt.text(bins[i] + bar_width/2, geral_hist[i] + 1, f'{geral_hist[i]:.1f}%', ha='center', va='bottom', fontsize=8, color='blue')

    plt.text(bins[i] + 1.5*bar_width, positiva_hist[i] + 1, f'{positiva_hist[i]:.1f}%', ha='center', va='bottom', fontsize=8, color='red')

plt.xlabel('Probabilidade (%)')
plt.ylabel('% da População')
plt.title('Distribuição das Probabilidades para População Geral e Classe Positiva')
plt.xticks(ticks=np.arange(0, 1.1, 0.1), labels=[f'{int(x*100)}%' for x in np.arange(0, 1.1, 0.1)])
plt.yticks(np.arange(0, 101, 10))

plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

zona_positiva_idx = np.where(bins[:-1] < limite_esquerdo)[0]
zona_negativa_idx = np.where(bins[:-1] > limite_direito)[0]
zona_mesa_idx = np.where((bins[:-1] >= limite_esquerdo) & (bins[:-1] <= limite_direito))[0]

soma_positiva_geral = np.sum(np.array(geral_hist)[zona_positiva_idx])
soma_positiva_spam = np.sum(np.array(positiva_hist)[zona_positiva_idx])

soma_negativa_geral = np.sum(np.array(geral_hist)[zona_negativa_idx])
soma_negativa_spam = np.sum(np.array(positiva_hist)[zona_negativa_idx])

soma_mesa_geral = np.sum(np.array(geral_hist)[zona_mesa_idx])
soma_mesa_spam = np.sum(np.array(positiva_hist)[zona_mesa_idx])

soma_total_geral = np.sum(geral_hist)
soma_total_spam = np.sum(positiva_hist)

porcent_positiva_geral = (soma_positiva_geral / soma_total_geral) * 100
porcent_positiva_spam = (soma_positiva_spam / soma_total_spam) * 100

porcent_negativa_geral = (soma_negativa_geral / soma_total_geral) * 100
porcent_negativa_spam = (soma_negativa_spam / soma_total_spam) * 100

porcent_mesa_geral = (soma_mesa_geral / soma_total_geral) * 100
porcent_mesa_spam = (soma_mesa_spam / soma_total_spam) * 100
plt.text(1.05, 50, f'Positiva: Geral {porcent_positiva_geral:.1f}%, Spam {porcent_positiva_spam:.1f}%', fontsize=10, color='green')
plt.text(1.05, 40, f'Mesa: Geral {porcent_mesa_geral:.1f}%, Spam {porcent_mesa_spam:.1f}%', fontsize=10, color='orange')
plt.text(1.05, 30, f'Negativa: Geral {porcent_negativa_geral:.1f}%, Spam {porcent_negativa_spam:.1f}%', fontsize=10, color='red')

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
cm = confusion_matrix(y_test, y_pred2)

TN, FP, FN, TP = cm.ravel()

plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])

plt.text(1.25, 1.25, f'TP={TP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
plt.text(0.25, 0.25, f'TN={TN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='white', weight='bold')
plt.text(0.25, 1.25, f'FP={FP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
plt.text(1.25, 0.25, f'FN={FN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')

plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão')
plt.show()

accuracy = accuracy_score(y_test, y_pred2)
print(f"Accuracy: {accuracy:.4f}")

precision = precision_score(y_test, y_pred2)
print(f"Precision: {precision:.4f}")

recall = recall_score(y_test, y_pred2)
print(f"Recall: {recall:.4f}")

f1 = f1_score(y_test, y_pred2)
print(f"F1-Score: {f1:.4f}")

from sklearn import metrics

area = metrics.roc_auc_score(y_test,y_proba_2)

import matplotlib.pyplot as plt

fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba_2)
roc_auc = metrics.auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

print(f"AUC-ROC: {roc_auc:.4f}")

precision, recall, _ = metrics.precision_recall_curve(y_test, y_proba_2)

auc_pr = metrics.average_precision_score(y_test, y_proba_2)

plt.figure()
plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % auc_pr)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()

print(f"AUC-PR: {auc_pr:.4f}")

contagem_positiva = np.sum(y_pred2 == 1)
contagem_negativa = np.sum(y_pred2 == 0)

total_instancias = len(y_pred2)

porcentagem_positiva = (contagem_positiva / total_instancias) * 100
porcentagem_negativa = (contagem_negativa / total_instancias) * 100

print(f"Porcentagem de instâncias positivas (Spam): {porcentagem_positiva:.2f}%")
print(f"Porcentagem de instâncias negativas (Ham): {porcentagem_negativa:.2f}%")

from sklearn import metrics
import matplotlib.pyplot as plt

fpr1, tpr1, thresholds1 = metrics.roc_curve(y_test, y_proba_1)
roc_auc1 = metrics.auc(fpr1, tpr1)

fpr2, tpr2, thresholds2 = metrics.roc_curve(y_test, y_proba_2)
roc_auc2 = metrics.auc(fpr2, tpr2)

plt.figure()

plt.plot(fpr1, tpr1, color='darkorange', lw=2, label='ROC curve 1 (AUC = %0.2f)' % roc_auc1)

plt.plot(fpr2, tpr2, color='blue', lw=2, label='ROC curve 2 (AUC = %0.2f)' % roc_auc2)

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - Comparison')

plt.legend(loc="lower right")

plt.show()

print(f"AUC-ROC para y_proba_1: {roc_auc1:.4f}")
print(f"AUC-ROC para y_proba_2: {roc_auc2:.4f}")

from sklearn import metrics
import matplotlib.pyplot as plt

precision1, recall1, _ = metrics.precision_recall_curve(y_test, y_proba_1)
auc_pr1 = metrics.average_precision_score(y_test, y_proba_1)

precision2, recall2, _ = metrics.precision_recall_curve(y_test, y_proba_2)
auc_pr2 = metrics.average_precision_score(y_test, y_proba_2)

plt.figure()

plt.plot(recall1, precision1, color='blue', lw=2, label='Precision-Recall curve 1 (AUC = %0.2f)' % auc_pr1)

plt.plot(recall2, precision2, color='green', lw=2, label='Precision-Recall curve 2 (AUC = %0.2f)' % auc_pr2)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve Comparison')
plt.legend(loc="lower left")

plt.show()

print(f"AUC-PR para y_proba_1: {auc_pr1:.4f}")
print(f"AUC-PR para y_proba_2: {auc_pr2:.4f}")